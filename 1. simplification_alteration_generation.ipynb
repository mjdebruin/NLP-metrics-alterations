{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key='sk-proj-###')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('sentence_pairs.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are 21 examples in the data, the last one being an example for the prompt we will build so the model has a reference for what \"simplified\" means in this context, the dataset will take the first 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "df = df.iloc[:20]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below will be passed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed row 1/20\n",
      "Processed row 2/20\n",
      "Processed row 3/20\n",
      "Processed row 4/20\n",
      "Processed row 5/20\n",
      "Processed row 6/20\n",
      "Processed row 7/20\n",
      "Processed row 8/20\n",
      "Processed row 9/20\n",
      "Processed row 10/20\n",
      "Processed row 11/20\n",
      "Processed row 12/20\n",
      "Processed row 13/20\n",
      "Processed row 14/20\n",
      "Processed row 15/20\n",
      "Processed row 16/20\n",
      "Processed row 17/20\n",
      "Processed row 18/20\n",
      "Processed row 19/20\n",
      "Processed row 20/20\n"
     ]
    }
   ],
   "source": [
    "def simplify_text(complex_text, example_complex, example_simple):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert at simplifying complex sentences while maintaining their core meaning. Simplify the given text in the style of the example provided.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"Example simplification:\n",
    "Complex: {example_complex}\n",
    "Simple: {example_simple}\n",
    "\n",
    "Please simplify this text in a similar way:\n",
    "Complex: {complex_text}\n",
    "Simple:\"\"\"}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example text for reference\n",
    "example_complex = \"Coal is likely to rival oil as the world's biggest source of energy in the next five years, with potentially disastrous consequences for the climate, according to the world's leading authority on energy economics.\"\n",
    "example_simple = \"Coal will probably rival oil as the world's biggest source of energy in the next five years. This might be a disaster for the climate.\"\n",
    "\n",
    "# Rename the original 'simple' column to 'original_simple' before generating new simplifications\n",
    "df = df.rename(columns={'simple': 'original_simple'})\n",
    "\n",
    "# Generate simplifications\n",
    "df['generated_simple'] = None\n",
    "\n",
    "for idx in df.index:\n",
    "    complex_text = df.loc[idx, 'complex']\n",
    "    simplified = simplify_text(complex_text, example_complex, example_simple)\n",
    "    df.loc[idx, 'generated_simple'] = simplified\n",
    "    time.sleep(1)  # API token rate limiter\n",
    "    print(f\"Processed row {idx + 1}/20\")\n",
    "\n",
    "# Save intermediate results\n",
    "df.to_csv('results_with_simplifications.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence alterations\n",
    "Alterations to the simplified sentence will be generated in a similar manner, for this we first need to change the example as to give the OpenAI model an idea of what our intention is.\n",
    "\n",
    "##### Actual simplification:\n",
    "Coal will probably rival oil as the world's biggest source of energy in the next five years. This might be a disaster for the climate. \n",
    "\n",
    "##### Fact Reversal:\n",
    "\"Coal will be much less important than oil as the world's biggest source of energy in the next five years. This might be great for the climate.\"\n",
    "\n",
    "\n",
    "##### Critical Information Omission:\n",
    "\"Coal will probably rival oil as the world's biggest source of energy in the next five years.\"\n",
    "(Omits the crucial climate impact information)\n",
    "\n",
    "##### Addition of Unsupported Information:\n",
    "\"Coal will probably rival oil as the world's biggest source of energy in the next five years. This might be a disaster for the climate, but new carbon capture technology will completely solve this problem.\"\n",
    "\n",
    "##### Subject/Object Reversal:\n",
    "\"Oil will probably be rivaled by coal as the world's biggest source of energy in the next five years. The climate might be a disaster for coal production.\"\n",
    "\n",
    "##### Partial Meaning Preservation with Altered Conclusions:\n",
    "\"Coal will probably rival oil as the world's biggest source of energy in the next five years. This will create many new jobs in the mining sector.\"\n",
    "(Keeps the energy fact but changes the conclusion from climate impact to economic impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed row 1/20\n",
      "Processed row 2/20\n",
      "Processed row 3/20\n",
      "Processed row 4/20\n",
      "Processed row 5/20\n",
      "Processed row 6/20\n",
      "Processed row 7/20\n",
      "Processed row 8/20\n",
      "Processed row 9/20\n",
      "Processed row 10/20\n",
      "Processed row 11/20\n",
      "Processed row 12/20\n",
      "Processed row 13/20\n",
      "Processed row 14/20\n",
      "Processed row 15/20\n",
      "Processed row 16/20\n",
      "Processed row 17/20\n",
      "Processed row 18/20\n",
      "Processed row 19/20\n",
      "Processed row 20/20\n"
     ]
    }
   ],
   "source": [
    "def generate_alterations(simplified_text):\n",
    "    example = \"\"\"Original: Coal will probably rival oil as the world's biggest source of energy in the next five years. This might be a disaster for the climate.\n",
    "\n",
    "1. Fact Reversal: Coal will be much less important than oil as the world's biggest source of energy in the next five years. This might be great for the climate.\n",
    "\n",
    "2. Critical Information Omission: Coal will probably rival oil as the world's biggest source of energy in the next five years.\n",
    "\n",
    "3. Addition of Unsupported Information: Coal will probably rival oil as the world's biggest source of energy in the next five years. This might be a disaster for the climate, but new carbon capture technology will completely solve this problem.\n",
    "\n",
    "4. Subject/Object Reversal: Oil will probably be rivaled by coal as the world's biggest source of energy in the next five years. The climate might be a disaster for coal production.\n",
    "\n",
    "5. Partial Meaning Preservation with Altered Conclusions: Coal will probably rival oil as the world's biggest source of energy in the next five years. This will create many new jobs in the mining sector.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Generate five alterations of the simplified text following the exact pattern shown in the example. Keep the same numbering and labels.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"Here's an example of the five alterations:\n",
    "\n",
    "{example}\n",
    "\n",
    "Now generate the same five types of alterations for this text:\n",
    "{simplified_text}\"\"\"}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        alterations = response.choices[0].message.content.strip().split('\\n')\n",
    "        result = {\n",
    "            'fact_reversal': None,\n",
    "            'info_omission': None,\n",
    "            'unsupported_info': None,\n",
    "            'subject_object_reversal': None,\n",
    "            'partial_meaning': None\n",
    "        }\n",
    "        \n",
    "        current_alteration = None\n",
    "        for line in alterations:\n",
    "            if \"1. Fact Reversal:\" in line:\n",
    "                result['fact_reversal'] = line.replace(\"1. Fact Reversal:\", \"\").strip()\n",
    "            elif \"2. Critical Information Omission:\" in line:\n",
    "                result['info_omission'] = line.replace(\"2. Critical Information Omission:\", \"\").strip()\n",
    "            elif \"3. Addition of Unsupported Information:\" in line:\n",
    "                result['unsupported_info'] = line.replace(\"3. Addition of Unsupported Information:\", \"\").strip()\n",
    "            elif \"4. Subject/Object Reversal:\" in line:\n",
    "                result['subject_object_reversal'] = line.replace(\"4. Subject/Object Reversal:\", \"\").strip()\n",
    "            elif \"5. Partial Meaning Preservation with Altered Conclusions:\" in line:\n",
    "                result['partial_meaning'] = line.replace(\"5. Partial Meaning Preservation with Altered Conclusions:\", \"\").strip()\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Add columns for each alteration type\n",
    "df['fact_reversal'] = None\n",
    "df['info_omission'] = None\n",
    "df['unsupported_info'] = None\n",
    "df['subject_object_reversal'] = None\n",
    "df['partial_meaning'] = None\n",
    "\n",
    "# Generate alterations\n",
    "for idx in df.index:\n",
    "    simplified_text = df.loc[idx, 'generated_simple']\n",
    "    alterations = generate_alterations(simplified_text)\n",
    "    \n",
    "    if alterations:\n",
    "        for column, value in alterations.items():\n",
    "            df.loc[idx, column] = value\n",
    "    \n",
    "    time.sleep(1)  # Similar delay for token rate limiting\n",
    "    print(f\"Processed row {idx + 1}/{len(df)}\")\n",
    "\n",
    "column_order = ['complex', 'original_simple', 'generated_simple', \n",
    "                'fact_reversal', 'info_omission', 'unsupported_info', \n",
    "                'subject_object_reversal', 'partial_meaning']\n",
    "df = df[column_order]\n",
    "\n",
    "df.to_csv('results_with_alterations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also save the dataframe to an excel file for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('results_with_alterations.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
